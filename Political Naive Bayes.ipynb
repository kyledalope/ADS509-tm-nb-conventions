{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"/Users/kyledalope/Downloads/nb-assignment-data/2020_Conventions.db\") #connects to db\n",
    "convention_cur = convention_db.cursor() #cursor object from db, to execute queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conventions\n"
     ]
    }
   ],
   "source": [
    "#Identify table names \n",
    "\n",
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "\n",
    "tables = convention_cur.fetchall()\n",
    "\n",
    "# Check if there are any tables\n",
    "if len(tables) == 0:\n",
    "    print(\"No tables found in the database.\")\n",
    "else:\n",
    "    # Print the table names\n",
    "    for table in tables:\n",
    "        print(table[0])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "party\n",
      "night\n",
      "speaker\n",
      "speaker_count\n",
      "time\n",
      "text\n",
      "text_len\n",
      "file\n"
     ]
    }
   ],
   "source": [
    "#identify column names of conventions table\n",
    "\n",
    "convention_cur.execute(\"PRAGMA table_info(conventions)\")\n",
    "columns = convention_cur.fetchall()\n",
    "\n",
    "# Check if there are any columns\n",
    "if len(columns) == 0:\n",
    "    print(\"No columns found in the table.\")\n",
    "else:\n",
    "    # Print the column names\n",
    "    for column in columns:\n",
    "        print(column[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "#whitespace_pattern = re.compile(r\"\\s+\")\n",
    "#hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    return [token for token in tokens if token.lower() not in sw]\n",
    "\n",
    "def remove_punctuation(text, punct_set=tw_punct) :\n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "#def tokenize(text) :\n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That\n",
    "    function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "\n",
    "    #return(text.split())\n",
    "\n",
    "def prepare(text, pipeline) :\n",
    "    for transform in pipeline:\n",
    "        text = transform(text)\n",
    "    return text\n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions\n",
    "                            ''')\n",
    "\n",
    "for row in query_results :\n",
    "    # store the results in convention_data\n",
    "    text = row[0]\n",
    "    party = row[1]\n",
    "\n",
    "    #clean and tokenize text column\n",
    "    text_clean = text\n",
    "    #text_clean = whitespace_pattern.sub(\" \", text_clean)\n",
    "    text_clean = remove_punctuation(text_clean)\n",
    "    text_clean = tokenize(text_clean)\n",
    "    text_clean = remove_stop(text_clean)\n",
    "    \n",
    "    #append cleaned text data to party column\n",
    "    convention_data.append([text_clean, party])\n",
    "    \n",
    "    \n",
    "    #pass # remove this\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['say',\n",
       "   'modestly',\n",
       "   'done',\n",
       "   'African',\n",
       "   'American',\n",
       "   'community',\n",
       "   'president',\n",
       "   'since',\n",
       "   'Abraham',\n",
       "   'Lincoln',\n",
       "   'first',\n",
       "   'Republican',\n",
       "   'president',\n",
       "   'done',\n",
       "   'three',\n",
       "   'years',\n",
       "   'Black',\n",
       "   'community',\n",
       "   'Joe',\n",
       "   'Biden',\n",
       "   'done',\n",
       "   '47',\n",
       "   'years'],\n",
       "  'Republican'],\n",
       " [['friend', 'Delaware’s', 'Joe', 'Biden'], 'Democratic'],\n",
       " [['question',\n",
       "   'choose',\n",
       "   'path',\n",
       "   'gives',\n",
       "   'us',\n",
       "   'best',\n",
       "   'chance',\n",
       "   'meet',\n",
       "   'universal',\n",
       "   'desires',\n",
       "   'go',\n",
       "   'back',\n",
       "   'time',\n",
       "   'people',\n",
       "   'treated',\n",
       "   'like',\n",
       "   'political',\n",
       "   'commodities',\n",
       "   'can’t',\n",
       "   'trusted',\n",
       "   'think',\n",
       "   'think',\n",
       "   'often',\n",
       "   'ancestors',\n",
       "   'struggled',\n",
       "   'freedom',\n",
       "   'think',\n",
       "   'giants',\n",
       "   'broad',\n",
       "   'shoulders',\n",
       "   'also',\n",
       "   'think',\n",
       "   'Joe',\n",
       "   'Biden',\n",
       "   'says',\n",
       "   '“If',\n",
       "   'aren’t',\n",
       "   'voting',\n",
       "   'ain’t',\n",
       "   'black”',\n",
       "   'argued',\n",
       "   'Republicans',\n",
       "   'would',\n",
       "   'put',\n",
       "   'us',\n",
       "   '“back',\n",
       "   'chains”',\n",
       "   'says',\n",
       "   'diversity',\n",
       "   'thought',\n",
       "   'black',\n",
       "   'community',\n",
       "   'Mr',\n",
       "   'Vice',\n",
       "   'President',\n",
       "   'look',\n",
       "   'black',\n",
       "   'sir',\n",
       "   'chains',\n",
       "   'mind',\n",
       "   'can’t',\n",
       "   'tell',\n",
       "   'vote',\n",
       "   'color',\n",
       "   'skin',\n",
       "   'Joe',\n",
       "   'Biden',\n",
       "   'backwards',\n",
       "   'thinker',\n",
       "   'world',\n",
       "   'craving',\n",
       "   'forwardlooking',\n",
       "   'leadership'],\n",
       "  'Republican'],\n",
       " [['husband',\n",
       "   'wife',\n",
       "   'attorneys',\n",
       "   'charged',\n",
       "   'pointing',\n",
       "   'guns',\n",
       "   'protesters'],\n",
       "  'Republican'],\n",
       " [['pledge',\n",
       "   'allegiance',\n",
       "   'flag',\n",
       "   'United',\n",
       "   'States',\n",
       "   'America',\n",
       "   'Republic',\n",
       "   'stands',\n",
       "   'one',\n",
       "   'nation',\n",
       "   'God',\n",
       "   'indivisible',\n",
       "   'liberty',\n",
       "   'justice'],\n",
       "  'Democratic'],\n",
       " [['Return', 'higher', 'standard'], 'Republican'],\n",
       " [['I’m',\n",
       "   'Congresswoman',\n",
       "   'Elise',\n",
       "   'Stefanik',\n",
       "   'honored',\n",
       "   'represent',\n",
       "   'New',\n",
       "   'York’s',\n",
       "   '21st',\n",
       "   'Congressional',\n",
       "   'District',\n",
       "   'cradle',\n",
       "   'American',\n",
       "   'revolution',\n",
       "   'It’s',\n",
       "   'almost',\n",
       "   '250',\n",
       "   'years',\n",
       "   'ago',\n",
       "   'brave',\n",
       "   'patriots',\n",
       "   'fought',\n",
       "   'Battles',\n",
       "   'Saratoga',\n",
       "   'turn',\n",
       "   'tide',\n",
       "   'Revolutionary',\n",
       "   'War',\n",
       "   'It’s',\n",
       "   '40',\n",
       "   'years',\n",
       "   'ago',\n",
       "   'Lake',\n",
       "   'Placid',\n",
       "   'team',\n",
       "   'amateur',\n",
       "   'hockey',\n",
       "   'players',\n",
       "   'outhustled',\n",
       "   'outskated',\n",
       "   'defeated',\n",
       "   'Soviet',\n",
       "   'Union',\n",
       "   'stunning',\n",
       "   'world',\n",
       "   'giving',\n",
       "   'us',\n",
       "   'unforgettable',\n",
       "   'Miracle',\n",
       "   'Ice',\n",
       "   'today',\n",
       "   'it’s',\n",
       "   'home',\n",
       "   'Fort',\n",
       "   'Drum',\n",
       "   'historic',\n",
       "   '10th',\n",
       "   'Mountain',\n",
       "   'Division',\n",
       "   'deployed',\n",
       "   'unit',\n",
       "   'US',\n",
       "   'Army',\n",
       "   'since',\n",
       "   '911',\n",
       "   'saw',\n",
       "   'firsthand',\n",
       "   'President',\n",
       "   'Trump',\n",
       "   'graciously',\n",
       "   'thank',\n",
       "   'honor',\n",
       "   'men',\n",
       "   'women',\n",
       "   'uniform',\n",
       "   'sign',\n",
       "   'largest',\n",
       "   'pay',\n",
       "   'raise',\n",
       "   'troops',\n",
       "   'decade',\n",
       "   'Since',\n",
       "   'nation’s',\n",
       "   'founding',\n",
       "   'generation',\n",
       "   'generation',\n",
       "   'everyday',\n",
       "   'Americans',\n",
       "   'served',\n",
       "   'sacrificed',\n",
       "   'preserve',\n",
       "   'strengthen',\n",
       "   'American',\n",
       "   'dream',\n",
       "   'vision',\n",
       "   'life',\n",
       "   'liberty',\n",
       "   'pursuit',\n",
       "   'happiness',\n",
       "   'idea',\n",
       "   'work',\n",
       "   'hard',\n",
       "   'dream',\n",
       "   'big',\n",
       "   'achieve',\n",
       "   'anything',\n",
       "   'imagine',\n",
       "   'believe',\n",
       "   'American',\n",
       "   'dream',\n",
       "   'I’ve',\n",
       "   'lived',\n",
       "   'Like',\n",
       "   'millions',\n",
       "   'Americans',\n",
       "   'grew',\n",
       "   'small',\n",
       "   'business',\n",
       "   'family',\n",
       "   'learned',\n",
       "   'values',\n",
       "   'hard',\n",
       "   'work',\n",
       "   'determination',\n",
       "   'first',\n",
       "   'person',\n",
       "   'immediate',\n",
       "   'family',\n",
       "   'graduate',\n",
       "   'college',\n",
       "   'ran',\n",
       "   'Congress',\n",
       "   'serve',\n",
       "   'Upstate',\n",
       "   'New',\n",
       "   'York',\n",
       "   'proudly',\n",
       "   'youngest',\n",
       "   'Republican',\n",
       "   'woman',\n",
       "   'elected',\n",
       "   'Congress',\n",
       "   'history',\n",
       "   'honored',\n",
       "   'support',\n",
       "   'President',\n",
       "   'Trump',\n",
       "   'reelection',\n",
       "   'know',\n",
       "   'candidate',\n",
       "   'stand',\n",
       "   'hardworking',\n",
       "   'families',\n",
       "   'protect',\n",
       "   'American',\n",
       "   'dream',\n",
       "   'future',\n",
       "   'generations',\n",
       "   'Since',\n",
       "   'first',\n",
       "   'day',\n",
       "   'office',\n",
       "   'President',\n",
       "   'Trump',\n",
       "   'fought',\n",
       "   'tirelessly',\n",
       "   'deliver',\n",
       "   'results',\n",
       "   'Americans',\n",
       "   'despite',\n",
       "   'Democrats’',\n",
       "   'baseless',\n",
       "   'illegal',\n",
       "   'impeachment',\n",
       "   'sham',\n",
       "   'media’s',\n",
       "   'endless',\n",
       "   'obsession',\n",
       "   'proud',\n",
       "   'lead',\n",
       "   'effort',\n",
       "   'standing',\n",
       "   'Constitution',\n",
       "   'President',\n",
       "   'Trump',\n",
       "   'importantly',\n",
       "   'American',\n",
       "   'people'],\n",
       "  'Republican'],\n",
       " [['military',\n",
       "   'prepared',\n",
       "   'rescue',\n",
       "   'mission',\n",
       "   'White',\n",
       "   'House',\n",
       "   'delayed',\n",
       "   'time',\n",
       "   'went',\n",
       "   'forward',\n",
       "   'Kayla',\n",
       "   'moved',\n",
       "   'another',\n",
       "   'location',\n",
       "   '18',\n",
       "   'months',\n",
       "   'brutal',\n",
       "   'torture',\n",
       "   'learned',\n",
       "   'ISIS',\n",
       "   'Kayla',\n",
       "   'killed',\n",
       "   'Obama',\n",
       "   'administration',\n",
       "   'kept',\n",
       "   'telling',\n",
       "   'us',\n",
       "   'everything',\n",
       "   'could',\n",
       "   'version',\n",
       "   'everything',\n",
       "   'wasn’t',\n",
       "   'enough',\n",
       "   'difference',\n",
       "   'President',\n",
       "   'makes',\n",
       "   'president',\n",
       "   'Trump',\n",
       "   'US',\n",
       "   'army',\n",
       "   'special',\n",
       "   'operators',\n",
       "   'conducted',\n",
       "   'raid',\n",
       "   'alBaghdadi’s',\n",
       "   'compound',\n",
       "   'learned',\n",
       "   'alBaghdadi',\n",
       "   'killed',\n",
       "   'learned',\n",
       "   'something',\n",
       "   'else',\n",
       "   'operators',\n",
       "   'named',\n",
       "   'Taskforce',\n",
       "   '814',\n",
       "   'August',\n",
       "   '14th',\n",
       "   'Kayla’s',\n",
       "   'birthday',\n",
       "   'mission',\n",
       "   'named',\n",
       "   'Operation',\n",
       "   'Kayla',\n",
       "   'Mueller',\n",
       "   'soldiers',\n",
       "   'thank',\n",
       "   'Kayla',\n",
       "   'looking'],\n",
       "  'Republican'],\n",
       " [['means',\n",
       "   'much',\n",
       "   'families',\n",
       "   'grow',\n",
       "   'single',\n",
       "   'parent',\n",
       "   'home',\n",
       "   'serve',\n",
       "   '600',\n",
       "   'boys',\n",
       "   'girls',\n",
       "   'right',\n",
       "   'daily',\n",
       "   'basis',\n",
       "   'even',\n",
       "   'COVID',\n",
       "   'us',\n",
       "   'give',\n",
       "   'moms',\n",
       "   'opportunity',\n",
       "   'take',\n",
       "   'money',\n",
       "   'check',\n",
       "   'paycheck',\n",
       "   'home',\n",
       "   'back',\n",
       "   'children',\n",
       "   'able',\n",
       "   'go',\n",
       "   'school',\n",
       "   'may',\n",
       "   'opportunity',\n",
       "   'otherwise',\n",
       "   'means',\n",
       "   'much',\n",
       "   'us',\n",
       "   'There’s',\n",
       "   'much',\n",
       "   'greater',\n",
       "   'opportunity',\n",
       "   'individuals',\n",
       "   'come',\n",
       "   'together',\n",
       "   'walk',\n",
       "   'life',\n",
       "   'People',\n",
       "   'really',\n",
       "   'able',\n",
       "   'see',\n",
       "   'positive',\n",
       "   'change',\n",
       "   'filled',\n",
       "   'hope',\n",
       "   'especially',\n",
       "   'throughout',\n",
       "   'time'],\n",
       "  'Republican'],\n",
       " [['Like',\n",
       "   'officials',\n",
       "   'didn’t',\n",
       "   'swear',\n",
       "   'oath',\n",
       "   'person',\n",
       "   'party',\n",
       "   'Public',\n",
       "   'servants',\n",
       "   'promise',\n",
       "   'defend',\n",
       "   'Constitution',\n",
       "   'uphold',\n",
       "   'laws',\n",
       "   'work',\n",
       "   'behalf',\n",
       "   'American',\n",
       "   'people',\n",
       "   'moment',\n",
       "   'President',\n",
       "   'Trump',\n",
       "   'took',\n",
       "   'office',\n",
       "   'he’s',\n",
       "   'used',\n",
       "   'position',\n",
       "   'benefit',\n",
       "   'rather',\n",
       "   'country',\n",
       "   'He’s',\n",
       "   'trampled',\n",
       "   'rule',\n",
       "   'law',\n",
       "   'trying',\n",
       "   'weaponize',\n",
       "   'justice',\n",
       "   'department',\n",
       "   'attack',\n",
       "   'enemies',\n",
       "   'protect',\n",
       "   'friends',\n",
       "   'Rather',\n",
       "   'standing',\n",
       "   'Vladimir',\n",
       "   'Putin',\n",
       "   'fawns',\n",
       "   'dictator',\n",
       "   'still',\n",
       "   'trying',\n",
       "   'interfere',\n",
       "   'elections',\n",
       "   'He’s',\n",
       "   'even',\n",
       "   'trying',\n",
       "   'sabotage',\n",
       "   'postal',\n",
       "   'service',\n",
       "   'keep',\n",
       "   'people',\n",
       "   'able',\n",
       "   'vote'],\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m word_cutoff \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m----> 3\u001b[0m tokens \u001b[39m=\u001b[39m [w \u001b[39mfor\u001b[39;49;00m t, p \u001b[39min\u001b[39;49;00m convention_data \u001b[39mfor\u001b[39;49;00m w \u001b[39min\u001b[39;49;00m prepare([t], [tokenize, remove_stop])]\n\u001b[1;32m      5\u001b[0m word_dist \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mFreqDist(tokens)\n\u001b[1;32m      7\u001b[0m feature_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m word_cutoff \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m----> 3\u001b[0m tokens \u001b[39m=\u001b[39m [w \u001b[39mfor\u001b[39;00m t, p \u001b[39min\u001b[39;00m convention_data \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m prepare([t], [tokenize, remove_stop])]\n\u001b[1;32m      5\u001b[0m word_dist \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mFreqDist(tokens)\n\u001b[1;32m      7\u001b[0m feature_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[24], line 31\u001b[0m, in \u001b[0;36mprepare\u001b[0;34m(text, pipeline)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprepare\u001b[39m(text, pipeline) :\n\u001b[1;32m     30\u001b[0m     \u001b[39mfor\u001b[39;00m transform \u001b[39min\u001b[39;00m pipeline:\n\u001b[0;32m---> 31\u001b[0m         text \u001b[39m=\u001b[39m transform(text)\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m text\n",
      "Cell \u001b[0;32mIn[21], line 27\u001b[0m, in \u001b[0;36mtokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtokenize\u001b[39m(text) :\n\u001b[1;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Splitting on whitespace rather than the book's tokenize function. That\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m    function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[39mreturn\u001b[39;00m(text\u001b[39m.\u001b[39;49msplit())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in prepare([t], [tokenize, remove_stop])]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    ret_dict = dict()\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_Your observations to come._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = 'Gotta fill this in'\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    estimated_party = \"Gotta fill this in\"\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "How do I trim whitespace? (n.d.). Stack Overflow. Retrieved June 3, 2023, from https://stackoverflow.com/questions/1185524/how-do-i-trim-whitespace\n",
    "\n",
    "‌sqlite3 — DB-API 2.0 interface for SQLite databases — Python 3.8.2 documentation. (n.d.). Docs.python.org. https://docs.python.org/3/library/sqlite3.html\n",
    "\n",
    "‌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
